# LLM Router â€” Cost-Aware, Confidence-Driven Model Routing

Most LLM systems face a bad tradeoff:
- **Always use API models** â†’ great quality, terrible cost  
- **Always use local models** â†’ cheap, but risky and unpredictable  

This project solves that by making **model selection an engineering decision**, not a guess.

Each request is routed to **small, medium, or API models** based on:
- Task type
- Confidence
- Context size
- Safety constraints

**The result**: Near-API quality at a fraction of the cost, with full explainability.

---

## ğŸš¨ The Problem

Naive LLM systems usually:
- Send everything to an API
- Or rely on brittle rules like "short â†’ local, long â†’ API"

These approaches fail when:
- The task is ambiguous
- Confidence is low
- Context silently overflows
- Quality degrades without warning

**This router explicitly models uncertainty.**

---

## ğŸ§  How Routing Works (Mental Model)

Routing is a deterministic decision pipeline:

```
       Request
          â”‚
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Static Rules   â”‚  (risk level, context size)
  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ ML Classifier  â”‚  (task + confidence)
  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Heuristics     â”‚  (context dominance, generation weight)
  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Safety Layer   â”‚  (context-window enforcement)
  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
       Final Tier
    (small / medium / api)
```

### Why **medium** exists

**Medium** is the uncertainty buffer:
- Too risky for small
- Not expensive enough to justify API
- Absorbs ambiguity safely

---

## âš–ï¸ Why This Is Different From "Always API"

| Naive System | This System |
|-------------|-------------|
| Cost scales linearly | Cost scales with confidence |
| No explainability | Every decision is explained |
| Silent failures | Context-window safety |
| No metrics | Traffic simulation + baselines |

This is not "prompt engineering".  
It's **decision engineering around LLMs**.

---

## ğŸ“Š Key Results (FP3)

From controlled traffic simulation:

- **~99.6% cost saved** vs API-only baseline
- Balanced routing across tiers:
  - `small` â†’ confident, cheap tasks
  - `medium` â†’ uncertain but safe
  - `api` â†’ large or risky contexts
- Deterministic behavior (golden routing test)

**Example FP3 distribution:**
- ~50% medium  
- ~30% API  
- ~20% small  

---

## â–¶ï¸ Run the Demo Locally

### 1. Install dependencies

```bash
pip install -r requirements.txt
```

### 2. Start the API

```bash
uvicorn app.main:app --reload
```

### 3. Run traffic simulation

```bash
python scripts/simulate_traffic_fp3.py
```

### 4. Start the frontend

```bash
cd frontend
npm install
npm run dev
```

---

## ğŸ–¼ï¸ Frontend

The UI visualizes:
- Chosen model tier
- Confidence score
- Routing explanation
- Latency and cost signals

*Screenshots go here*

---

## ğŸ§© Tech Stack

| Component | Technology |
|-----------|-----------|
| **Routing** | Deterministic rules + heuristics + ML |
| **Classifier** | TF-IDF + Logistic Regression |
| **API** | FastAPI |
| **Cache** | Redis |
| **Metrics** | Prometheus |
| **Frontend** | React + Tailwind |

---

## ğŸ¯ Who This Is For

- LLM engineers
- MLOps / infra engineers
- Teams building cost-sensitive AI systems

**This project is intentionally boring, explainable, and reliable.**  
That's how real systems win.

---

## ğŸ“– Documentation

- [Architecture Overview](./ARCHITECTURE.md) â€” deep dive into design decisions
- API documentation â€” available at `/docs` when running locally

---

## ğŸ¤ Contributing

Contributions are welcome. Please open an issue first to discuss major changes.

---

## ğŸ”— Related Resources

- [Experiments & Evidence](./EXPERIMENTS.md)